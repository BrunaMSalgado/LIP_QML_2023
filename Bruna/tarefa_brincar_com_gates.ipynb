{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates.embeddings import AngleEmbedding\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 90548\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Electron_Multi</th>\n",
       "      <th>FatJet1_Eta</th>\n",
       "      <th>FatJet1_Mass</th>\n",
       "      <th>FatJet1_PT</th>\n",
       "      <th>FatJet1_Phi</th>\n",
       "      <th>FatJet1_Tau1</th>\n",
       "      <th>FatJet1_Tau2</th>\n",
       "      <th>FatJet1_Tau3</th>\n",
       "      <th>FatJet1_Tau4</th>\n",
       "      <th>FatJet1_Tau5</th>\n",
       "      <th>...</th>\n",
       "      <th>gen_decay2</th>\n",
       "      <th>gen_decay_filter</th>\n",
       "      <th>gen_filter</th>\n",
       "      <th>gen_label</th>\n",
       "      <th>gen_n_btags</th>\n",
       "      <th>gen_sample</th>\n",
       "      <th>gen_sample_filter</th>\n",
       "      <th>gen_split</th>\n",
       "      <th>gen_weights</th>\n",
       "      <th>gen_xsec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.408853</td>\n",
       "      <td>15.150869</td>\n",
       "      <td>339.182312</td>\n",
       "      <td>2.350262</td>\n",
       "      <td>1.396943</td>\n",
       "      <td>0.710451</td>\n",
       "      <td>0.109013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>PyDelphes</td>\n",
       "      <td>signal</td>\n",
       "      <td>1</td>\n",
       "      <td>tZFCNC</td>\n",
       "      <td>tZFCNC_PyDelphes</td>\n",
       "      <td>test</td>\n",
       "      <td>7.762202e-09</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.481838</td>\n",
       "      <td>7.208333</td>\n",
       "      <td>247.036240</td>\n",
       "      <td>-2.280740</td>\n",
       "      <td>0.428710</td>\n",
       "      <td>0.205213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>PyDelphes</td>\n",
       "      <td>signal</td>\n",
       "      <td>1</td>\n",
       "      <td>tZFCNC</td>\n",
       "      <td>tZFCNC_PyDelphes</td>\n",
       "      <td>val</td>\n",
       "      <td>7.762202e-09</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.476267</td>\n",
       "      <td>94.220718</td>\n",
       "      <td>238.014694</td>\n",
       "      <td>-1.788097</td>\n",
       "      <td>94.256210</td>\n",
       "      <td>2.418446</td>\n",
       "      <td>1.585315</td>\n",
       "      <td>1.127324</td>\n",
       "      <td>0.431098</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>PyDelphes</td>\n",
       "      <td>signal</td>\n",
       "      <td>1</td>\n",
       "      <td>tZFCNC</td>\n",
       "      <td>tZFCNC_PyDelphes</td>\n",
       "      <td>train</td>\n",
       "      <td>7.762249e-09</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.647480</td>\n",
       "      <td>13.459283</td>\n",
       "      <td>230.971832</td>\n",
       "      <td>-1.032663</td>\n",
       "      <td>1.227122</td>\n",
       "      <td>0.467150</td>\n",
       "      <td>0.164008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>PyDelphes</td>\n",
       "      <td>signal</td>\n",
       "      <td>1</td>\n",
       "      <td>tZFCNC</td>\n",
       "      <td>tZFCNC_PyDelphes</td>\n",
       "      <td>train</td>\n",
       "      <td>7.762249e-09</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.106436</td>\n",
       "      <td>97.490242</td>\n",
       "      <td>698.399902</td>\n",
       "      <td>-3.059983</td>\n",
       "      <td>36.555862</td>\n",
       "      <td>2.937936</td>\n",
       "      <td>1.799140</td>\n",
       "      <td>1.093004</td>\n",
       "      <td>0.589724</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>PyDelphes</td>\n",
       "      <td>signal</td>\n",
       "      <td>1</td>\n",
       "      <td>tZFCNC</td>\n",
       "      <td>tZFCNC_PyDelphes</td>\n",
       "      <td>train</td>\n",
       "      <td>7.762249e-09</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Electron_Multi  FatJet1_Eta  FatJet1_Mass  FatJet1_PT  FatJet1_Phi  \\\n",
       "0               2     1.408853     15.150869  339.182312     2.350262   \n",
       "1               1    -2.481838      7.208333  247.036240    -2.280740   \n",
       "2               0     1.476267     94.220718  238.014694    -1.788097   \n",
       "3               1     0.647480     13.459283  230.971832    -1.032663   \n",
       "4               0     2.106436     97.490242  698.399902    -3.059983   \n",
       "\n",
       "   FatJet1_Tau1  FatJet1_Tau2  FatJet1_Tau3  FatJet1_Tau4  FatJet1_Tau5  ...  \\\n",
       "0      1.396943      0.710451      0.109013      0.000000      0.000000  ...   \n",
       "1      0.428710      0.205213      0.000000      0.000000      0.000000  ...   \n",
       "2     94.256210      2.418446      1.585315      1.127324      0.431098  ...   \n",
       "3      1.227122      0.467150      0.164008      0.000000      0.000000  ...   \n",
       "4     36.555862      2.937936      1.799140      1.093004      0.589724  ...   \n",
       "\n",
       "   gen_decay2  gen_decay_filter  gen_filter  gen_label  gen_n_btags  \\\n",
       "0           0              None   PyDelphes     signal            1   \n",
       "1           0              None   PyDelphes     signal            1   \n",
       "2           0              None   PyDelphes     signal            1   \n",
       "3           0              None   PyDelphes     signal            1   \n",
       "4           0              None   PyDelphes     signal            1   \n",
       "\n",
       "   gen_sample  gen_sample_filter  gen_split   gen_weights  gen_xsec  \n",
       "0      tZFCNC   tZFCNC_PyDelphes       test  7.762202e-09  0.001285  \n",
       "1      tZFCNC   tZFCNC_PyDelphes        val  7.762202e-09  0.001285  \n",
       "2      tZFCNC   tZFCNC_PyDelphes      train  7.762249e-09  0.001285  \n",
       "3      tZFCNC   tZFCNC_PyDelphes      train  7.762249e-09  0.001285  \n",
       "4      tZFCNC   tZFCNC_PyDelphes      train  7.762249e-09  0.001285  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read the HDF5 file using pandas\n",
    "data_frame_fcnc = pd.read_hdf('fcnc_pythia_sanitised_features.h5')\n",
    "\n",
    "# Get the number of rows\n",
    "num_rows = data_frame_fcnc.shape[0]\n",
    "\n",
    "print('Number of rows: {}'.format(num_rows))\n",
    "\n",
    "# Explore the data\n",
    "data_frame_fcnc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1002490\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Electron_Multi</th>\n",
       "      <th>FatJet1_Eta</th>\n",
       "      <th>FatJet1_Mass</th>\n",
       "      <th>FatJet1_PT</th>\n",
       "      <th>FatJet1_Phi</th>\n",
       "      <th>FatJet1_Tau1</th>\n",
       "      <th>FatJet1_Tau2</th>\n",
       "      <th>FatJet1_Tau3</th>\n",
       "      <th>FatJet1_Tau4</th>\n",
       "      <th>FatJet1_Tau5</th>\n",
       "      <th>...</th>\n",
       "      <th>gen_decay2</th>\n",
       "      <th>gen_decay_filter</th>\n",
       "      <th>gen_filter</th>\n",
       "      <th>gen_label</th>\n",
       "      <th>gen_n_btags</th>\n",
       "      <th>gen_sample</th>\n",
       "      <th>gen_sample_filter</th>\n",
       "      <th>gen_split</th>\n",
       "      <th>gen_weights</th>\n",
       "      <th>gen_xsec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.988600</td>\n",
       "      <td>52.710262</td>\n",
       "      <td>229.350952</td>\n",
       "      <td>0.728242</td>\n",
       "      <td>36.148926</td>\n",
       "      <td>23.039709</td>\n",
       "      <td>16.949991</td>\n",
       "      <td>14.424411</td>\n",
       "      <td>12.000529</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2L</td>\n",
       "      <td>HT250to500</td>\n",
       "      <td>bkg</td>\n",
       "      <td>1</td>\n",
       "      <td>Zjj</td>\n",
       "      <td>Zjj_HT250to500</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>11.9635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>61.115589</td>\n",
       "      <td>315.538910</td>\n",
       "      <td>-0.863614</td>\n",
       "      <td>32.592808</td>\n",
       "      <td>22.366640</td>\n",
       "      <td>16.285843</td>\n",
       "      <td>13.938633</td>\n",
       "      <td>11.180016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2L</td>\n",
       "      <td>HT250to500</td>\n",
       "      <td>bkg</td>\n",
       "      <td>1</td>\n",
       "      <td>Zjj</td>\n",
       "      <td>Zjj_HT250to500</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>11.9635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.479911</td>\n",
       "      <td>98.012802</td>\n",
       "      <td>251.109573</td>\n",
       "      <td>-3.133624</td>\n",
       "      <td>90.252274</td>\n",
       "      <td>33.646885</td>\n",
       "      <td>30.612156</td>\n",
       "      <td>27.973904</td>\n",
       "      <td>23.729696</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2L</td>\n",
       "      <td>HT250to500</td>\n",
       "      <td>bkg</td>\n",
       "      <td>1</td>\n",
       "      <td>Zjj</td>\n",
       "      <td>Zjj_HT250to500</td>\n",
       "      <td>val</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>11.9635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926899</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>240.909348</td>\n",
       "      <td>0.835656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2L</td>\n",
       "      <td>HT250to500</td>\n",
       "      <td>bkg</td>\n",
       "      <td>1</td>\n",
       "      <td>Zjj</td>\n",
       "      <td>Zjj_HT250to500</td>\n",
       "      <td>val</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>11.9635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.781194</td>\n",
       "      <td>72.234299</td>\n",
       "      <td>206.020386</td>\n",
       "      <td>-0.320449</td>\n",
       "      <td>48.886372</td>\n",
       "      <td>20.743645</td>\n",
       "      <td>16.572512</td>\n",
       "      <td>13.070706</td>\n",
       "      <td>11.269534</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2L</td>\n",
       "      <td>HT250to500</td>\n",
       "      <td>bkg</td>\n",
       "      <td>1</td>\n",
       "      <td>Zjj</td>\n",
       "      <td>Zjj_HT250to500</td>\n",
       "      <td>val</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>11.9635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Electron_Multi  FatJet1_Eta  FatJet1_Mass  FatJet1_PT  FatJet1_Phi  \\\n",
       "0               2    -1.988600     52.710262  229.350952     0.728242   \n",
       "1               0     0.528382     61.115589  315.538910    -0.863614   \n",
       "2               0     1.479911     98.012802  251.109573    -3.133624   \n",
       "3               2     0.926899     -0.000007  240.909348     0.835656   \n",
       "4               0     0.781194     72.234299  206.020386    -0.320449   \n",
       "\n",
       "   FatJet1_Tau1  FatJet1_Tau2  FatJet1_Tau3  FatJet1_Tau4  FatJet1_Tau5  ...  \\\n",
       "0     36.148926     23.039709     16.949991     14.424411     12.000529  ...   \n",
       "1     32.592808     22.366640     16.285843     13.938633     11.180016  ...   \n",
       "2     90.252274     33.646885     30.612156     27.973904     23.729696  ...   \n",
       "3      0.000000      0.000000      0.000000      0.000000      0.000000  ...   \n",
       "4     48.886372     20.743645     16.572512     13.070706     11.269534  ...   \n",
       "\n",
       "   gen_decay2  gen_decay_filter  gen_filter  gen_label  gen_n_btags  \\\n",
       "0           0                2L  HT250to500        bkg            1   \n",
       "1           0                2L  HT250to500        bkg            1   \n",
       "2           0                2L  HT250to500        bkg            1   \n",
       "3           0                2L  HT250to500        bkg            1   \n",
       "4           0                2L  HT250to500        bkg            1   \n",
       "\n",
       "   gen_sample  gen_sample_filter  gen_split  gen_weights  gen_xsec  \n",
       "0         Zjj     Zjj_HT250to500      train     0.000018   11.9635  \n",
       "1         Zjj     Zjj_HT250to500       test     0.000018   11.9635  \n",
       "2         Zjj     Zjj_HT250to500        val     0.000018   11.9635  \n",
       "3         Zjj     Zjj_HT250to500        val     0.000018   11.9635  \n",
       "4         Zjj     Zjj_HT250to500        val     0.000018   11.9635  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the HDF5 file using pandas\n",
    "data_frame_bkg = pd.read_hdf('bkg_pythia_sanitised_features.h5')\n",
    "\n",
    "# Get the number of rows\n",
    "num_rows = data_frame_bkg.shape[0]\n",
    "\n",
    "print('Number of rows: {}'.format(num_rows))\n",
    "\n",
    "# Explore the data\n",
    "data_frame_bkg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization\n",
    "\n",
    "# copy the data to a new dataframe\n",
    "data_frame_fcnc_norm = data_frame_fcnc.copy()\n",
    "data_frame_bkg_norm = data_frame_bkg.copy()\n",
    "\n",
    "# normalize the data except the categorical features and the weights\n",
    "for feature in data_frame_fcnc.columns:\n",
    "    if feature in ['gen_decay_filter', 'gen_filter', 'gen_label', 'gen_n_btags', 'gen_sample', 'gen_sample_filter', 'gen_split', 'gen_decay2','gen_decay1', 'gen_xsec']:\n",
    "        pass\n",
    "    else: \n",
    "        data_frame_fcnc_norm[feature] = (data_frame_fcnc[feature] - data_frame_fcnc[feature].mean()) / data_frame_fcnc[feature].std()\n",
    "        \n",
    "for feature in data_frame_bkg.columns:\n",
    "    if feature in ['gen_decay_filter', 'gen_filter', 'gen_label', 'gen_n_btags', 'gen_sample', 'gen_sample_filter', 'gen_split','gen_decay2','gen_decay1','gen_xsec']:\n",
    "        pass\n",
    "    else:  \n",
    "        data_frame_bkg_norm[feature] = (data_frame_bkg[feature] - data_frame_bkg[feature].mean()) / data_frame_bkg[feature].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pennylane (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original data into train, validation and test sets for each dataset\n",
    "data_frame_fcnc_train = data_frame_fcnc.loc[data_frame_fcnc['gen_split'] == 'train']\n",
    "data_frame_bkg_train =  data_frame_bkg.loc[data_frame_bkg['gen_split'] == 'train']\n",
    "\n",
    "data_frame_fcnc_test = data_frame_fcnc.loc[data_frame_fcnc['gen_split'] == 'test']\n",
    "data_frame_bkg_test =  data_frame_bkg.loc[data_frame_bkg['gen_split'] == 'test']\n",
    "\n",
    "data_frame_fcnc_val = data_frame_fcnc.loc[data_frame_fcnc['gen_split'] == 'val']\n",
    "data_frame_bkg_val =  data_frame_bkg.loc[data_frame_bkg['gen_split'] == 'val']\n",
    "\n",
    "\n",
    "# get 500 points of each dataset and  join the datasets (randomly)\n",
    "train_fcnc = data_frame_fcnc_train.sample(n=500, random_state=42)\n",
    "train_bkg = data_frame_bkg_train.sample(n=500, random_state=42)\n",
    "train = pd.concat([train_fcnc, train_bkg])\n",
    "train = train.sample(frac=1, random_state=42)\n",
    "\n",
    "test_fcnc = data_frame_fcnc_test.sample(n=500, random_state=42)\n",
    "test_bkg = data_frame_bkg_test.sample(n=500, random_state=42)\n",
    "test= pd.concat([test_fcnc, test_bkg])\n",
    "test = test.sample(frac=1,random_state=42)\n",
    "\n",
    "val_fnc = data_frame_fcnc_val.sample(n=500, random_state=42)\n",
    "val_bkg = data_frame_bkg_val.sample(n=500, random_state=42)\n",
    "val = pd.concat([val_fnc, val_bkg])\n",
    "val = val.sample(frac=1, random_state=42)\n",
    "\n",
    "# get the weights for each dataset\n",
    "w_train = train[['gen_xsec']]\n",
    "w_test = test[['gen_xsec']]\n",
    "w_val = val[['gen_xsec']]\n",
    "\n",
    "\n",
    "# change the signal and bkg labels to 0 and 1 and get the labels for each dataset\n",
    "train = train.replace(['signal'], 1)\n",
    "train= train.replace(['bkg'], 0)\n",
    "y_train = train[['gen_label']]\n",
    "x_train = train[['MissingET_MET', 'Jet1_BTag']]\n",
    "\n",
    "test = test.replace(['signal'], 1)\n",
    "test= test.replace(['bkg'], 0)\n",
    "y_test = test[['gen_label']]\n",
    "x_test = test[['MissingET_MET', 'Jet1_BTag']]\n",
    "\n",
    "val = val.replace(['signal'], 1)\n",
    "val= val.replace(['bkg'], 0)\n",
    "y_val = val[['gen_label']]\n",
    "x_val = val[['MissingET_MET', 'Jet1_BTag']]\n",
    "\n",
    "y_train_arr = np.concatenate(y_train.values, axis=0 )\n",
    "y_val_arr = np.concatenate( y_val.values, axis=0 )\n",
    "y_test_arr = np.concatenate( y_test.values, axis=0 )\n",
    "\n",
    "# Renormalize data weights\n",
    "w_train[y_train_arr == 1] = (w_train[y_train_arr == 1] / w_train[y_train_arr == 1].sum()) * y_train_arr.shape[0] / 2\n",
    "w_train[y_train_arr == 0] = (w_train[y_train_arr == 0] / w_train[y_train_arr == 0].sum()) * y_train_arr.shape[0] / 2\n",
    "        \n",
    "w_test[y_test_arr == 1] = (w_test[y_test_arr == 1] / w_test[y_test_arr == 1].sum()) * w_test.shape[0] / 2\n",
    "w_test[y_test_arr == 0] = (w_test[y_test_arr == 0] / w_test[y_test_arr == 0].sum()) * w_test.shape[0] / 2\n",
    "        \n",
    "w_val[y_test_arr == 1] = (w_val[y_test_arr == 1] / w_val[y_test_arr == 1].sum()) * w_val.shape[0] / 2\n",
    "w_val[y_test_arr == 0] = (w_val[y_test_arr == 0] / w_val[y_test_arr == 0].sum()) * w_val.shape[0] / 2\n",
    "\n",
    "# Concatenate features\n",
    "X = np.concatenate([x_train, x_test,x_val])\n",
    "\n",
    "# Normalize the data for angle embeding  (Put the data between -pi and pi)\n",
    "X = (((X - X.min()) / (X.max() - X.min())) * 2 - 1) * (np.pi)\n",
    "\n",
    "# Split the features array into train, validation and test sets\n",
    "x_train = X[:1000]\n",
    "x_test = X[1000:2000]\n",
    "x_val = X[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy function\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "# quantum circuit function\n",
    "def circuit(n_features, n_layers, weights, x):\n",
    "        # Embedding\n",
    "        \n",
    "        qml.AngleEmbedding(x,range (0, n_features),rotation=\"X\" )\n",
    "\n",
    "        # For every layer\n",
    "        for layer in range(n_layers):\n",
    "            W1 = weights[layer]\n",
    "\n",
    "            # Define Rotations\n",
    "            for i in range(0,n_features):\n",
    "                qml.Rot(W1[i, 0], W1[i, 1], W1[i, 2], wires=i)\n",
    "\n",
    "            # Entanglement\n",
    "            if n_features != 1:\n",
    "                if n_features > 2:\n",
    "                    for i in range(n_features):\n",
    "                        if i == n_features - 1:\n",
    "                            qml.CNOT(wires=[i, 0])\n",
    "                        else:\n",
    "                            qml.CNOT(wires=[i, i + 1])\n",
    "                else:\n",
    "                    qml.CNOT(wires=[1, 0])\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# classifier function    \n",
    "def classifier(n_features, n_layers, weights, x):\n",
    "        #c = circuit(n_features, n_layers, weights, x)\n",
    "        dev=qml.device(\"default.qubit\", wires=n_features)\n",
    "        return qml.QNode(circuit, dev)(n_features, n_layers, weights, x)\n",
    "    \n",
    "# cost function    \n",
    "def cost(n_features, n_layers,weights,X,Y,W):  \n",
    "        # Compute predictions\n",
    "        y_scores = [(classifier(n_features, n_layers,weights, x) + 1) / 2 for x in X]\n",
    "\n",
    "        loss = square_loss(Y, y_scores)\n",
    "        loss = loss * W\n",
    "        loss = loss.sum()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "# train step function    \n",
    "def train_step(n_features, n_layers,x_train,y_train, w_train, weights, opt,desc='Training'):\n",
    "        \n",
    "        # Only require grad if necessary\n",
    "        x_train = np.array(x_train, requires_grad=False)\n",
    "        y_train = np.array(y_train, requires_grad=True)\n",
    "        w_train = np.array(w_train, requires_grad=False)\n",
    "\n",
    "        # Compute cost and update weights\n",
    "        weights, loss = opt.step_and_cost(cost, n_features, n_layers,weights, X=x_train, Y=y_train, W=w_train)\n",
    "\n",
    "        return loss, weights\n",
    "    \n",
    "# validation step function\n",
    "def validation_step(n_features, n_layers, x_val, y_val, w_val, weights, best_score, epoch_number, best_score_epoch,best_weights,desc='Validation'):\n",
    "    X_val = np.array(x_val, requires_grad=False)\n",
    "    Y_val = np.array(y_val, requires_grad=False)\n",
    "    W_val = np.array(w_val, requires_grad=False)\n",
    "\n",
    "    y_scores = np.array([classifier(n_features, n_layers, weights, x) for x in X_val])\n",
    "    y_scores = (y_scores + 1) / 2\n",
    "\n",
    "    W_val[Y_val == 1] = (W_val[Y_val == 1] / W_val[Y_val == 1].sum()) * W_val.shape[0] / 2\n",
    "    W_val[Y_val == 0] = (W_val[Y_val == 0] / W_val[Y_val == 0].sum()) * W_val.shape[0] / 2\n",
    "\n",
    "    auc_score = roc_auc_score(y_true=Y_val, y_score=y_scores, sample_weight=W_val)\n",
    "    loss = cost(n_features, n_layers, weights, X_val, Y_val, W_val)\n",
    "\n",
    "\n",
    "    if best_score is None or auc_score > best_score:\n",
    "        best_score = auc_score\n",
    "        best_score_epoch = epoch_number\n",
    "        best_weights = weights\n",
    "\n",
    "    tqdm.write(f\"Epoch: {epoch_number}, Validation Loss: {loss:.4f}, AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "    return best_score, best_score_epoch, best_weights\n",
    "        \n",
    "        \n",
    "# train function\n",
    "def train(n_features, n_layers, x_train, y_train, learning_rate, weights, max_epochs, epoch_number):\n",
    "    opt = AdamOptimizer(learning_rate)\n",
    "    best_score = None\n",
    "    best_weights = None\n",
    "    best_score_epoch = None\n",
    "\n",
    "    with tqdm(total=max_epochs, desc='Epoch', unit='epoch') as pbar:\n",
    "        for epoch in range(epoch_number, max_epochs):\n",
    "            epoch_number = epoch\n",
    "\n",
    "            loss, nf_nl_weights = train_step(n_features, n_layers, x_train, y_train, w_train, weights, opt, desc='Training')\n",
    "            \n",
    "            # Log variable values using tqdm.write\n",
    "            tqdm.write(f\"Epoch: {epoch_number:}, Loss: {loss:.4f}\")\n",
    "            \n",
    "            \n",
    "            weights = nf_nl_weights[2:]\n",
    "            weights = weights[0]\n",
    "\n",
    "            if epoch_number == max_epochs - 1 or (epoch_number+1)%5==0:\n",
    "                best_score, best_score_epoch, best_weights = validation_step(n_features, n_layers, x_val, y_val, w_val, weights, best_score, epoch_number, best_score_epoch, best_weights,desc='Validation')\n",
    "                # early stopping\n",
    "                if epoch_number - best_score_epoch > 30 and epoch_number > 80:\n",
    "                    tqdm.write(f\"Early stopping at epoch {epoch_number}\")\n",
    "                    break\n",
    "\n",
    "            pbar.update(1)  # Update progress bar\n",
    "        tqdm.write(f\"Best Score: {best_score:.4f}\")            \n",
    "        \n",
    "    return best_score, best_weights\n",
    "\n",
    "def test(n_features, n_layers,x_test,y_test,w_test, weights):\n",
    "        # Remove grad\n",
    "        X_test = np.array(x_test, requires_grad=False)\n",
    "        Y_test = np.array(y_test, requires_grad=False)\n",
    "        W_test = np.array(w_test, requires_grad=False)\n",
    "\n",
    "        # This will be between -1 and 1, we need to convert to between 0 and 1\n",
    "        y_scores = np.array([classifier(n_features, n_layers,weights, x) for x in X_test])\n",
    "        y_scores = (y_scores + 1) / 2\n",
    "\n",
    "        # Renormalize weights\n",
    "        W_test[Y_test == 1] = (W_test[Y_test == 1] / W_test[Y_test == 1].sum()) * W_test.shape[0] / 2\n",
    "        W_test[Y_test == 0] = (W_test[Y_test == 0] / W_test[Y_test == 0].sum()) * W_test.shape[0] / 2\n",
    "\n",
    "        # Calculate ROC\n",
    "        auc_score = roc_auc_score(y_true=Y_test, y_score=y_scores, sample_weight=W_test)\n",
    "        \n",
    "        return auc_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe139daa2f046be85876cbe0a66f674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 507.6642\n",
      "Epoch: 1, Loss: 507.0090\n",
      "Epoch: 2, Loss: 505.8304\n",
      "Epoch: 3, Loss: 504.0940\n",
      "Epoch: 4, Loss: 501.7893\n",
      "Epoch: 4, Validation Loss: 493.7559, AUC Score: 0.2792\n",
      "Epoch: 5, Loss: 498.9076\n",
      "Epoch: 6, Loss: 495.4493\n",
      "Epoch: 7, Loss: 491.4242\n",
      "Epoch: 8, Loss: 486.8508\n",
      "Epoch: 9, Loss: 481.7572\n",
      "Epoch: 9, Validation Loss: 471.3341, AUC Score: 0.2791\n",
      "Epoch: 10, Loss: 476.1815\n",
      "Epoch: 11, Loss: 470.1706\n",
      "Epoch: 12, Loss: 463.7779\n",
      "Epoch: 13, Loss: 457.0577\n",
      "Epoch: 14, Loss: 450.0574\n",
      "Epoch: 14, Validation Loss: 438.5077, AUC Score: 0.2794\n",
      "Epoch: 15, Loss: 442.8126\n",
      "Epoch: 16, Loss: 435.3477\n",
      "Epoch: 17, Loss: 427.6760\n",
      "Epoch: 18, Loss: 419.8019\n",
      "Epoch: 19, Loss: 411.7330\n",
      "Epoch: 19, Validation Loss: 399.9954, AUC Score: 0.2798\n",
      "Epoch: 20, Loss: 403.4872\n",
      "Epoch: 21, Loss: 395.0909\n",
      "Epoch: 22, Loss: 386.5757\n",
      "Epoch: 23, Loss: 377.9750\n",
      "Epoch: 24, Loss: 369.3239\n",
      "Epoch: 24, Validation Loss: 358.1327, AUC Score: 0.2806\n",
      "Epoch: 25, Loss: 360.6597\n",
      "Epoch: 26, Loss: 352.0220\n",
      "Epoch: 27, Loss: 343.4526\n",
      "Epoch: 28, Loss: 334.9941\n",
      "Epoch: 29, Loss: 326.6897\n",
      "Epoch: 29, Validation Loss: 316.9704, AUC Score: 0.2801\n",
      "Epoch: 30, Loss: 318.5822\n",
      "Epoch: 31, Loss: 310.7139\n",
      "Epoch: 32, Loss: 303.1251\n",
      "Epoch: 33, Loss: 295.8528\n",
      "Epoch: 34, Loss: 288.9295\n",
      "Epoch: 34, Validation Loss: 281.5392, AUC Score: 0.2790\n",
      "Epoch: 35, Loss: 282.3823\n",
      "Epoch: 36, Loss: 276.2319\n",
      "Epoch: 37, Loss: 270.4922\n",
      "Epoch: 38, Loss: 265.1696\n",
      "Epoch: 39, Loss: 260.2634\n",
      "Epoch: 39, Validation Loss: 255.5502, AUC Score: 0.5591\n",
      "Epoch: 40, Loss: 255.7650\n",
      "Epoch: 41, Loss: 251.6594\n",
      "Epoch: 42, Loss: 247.9255\n",
      "Epoch: 43, Loss: 244.5380\n",
      "Epoch: 44, Loss: 241.4692\n",
      "Epoch: 44, Validation Loss: 238.9753, AUC Score: 0.6847\n",
      "Epoch: 45, Loss: 238.6904\n",
      "Epoch: 46, Loss: 236.1743\n",
      "Epoch: 47, Loss: 233.8954\n",
      "Epoch: 48, Loss: 231.8307\n",
      "Epoch: 49, Loss: 229.9599\n",
      "Epoch: 49, Validation Loss: 228.8959, AUC Score: 0.6908\n",
      "Epoch: 50, Loss: 228.2645\n",
      "Epoch: 51, Loss: 226.7275\n",
      "Epoch: 52, Loss: 225.3332\n",
      "Epoch: 53, Loss: 224.0672\n",
      "Epoch: 54, Loss: 222.9160\n",
      "Epoch: 54, Validation Loss: 222.7206, AUC Score: 0.6921\n",
      "Epoch: 55, Loss: 221.8668\n",
      "Epoch: 56, Loss: 220.9081\n",
      "Epoch: 57, Loss: 220.0293\n",
      "Epoch: 58, Loss: 219.2206\n",
      "Epoch: 59, Loss: 218.4738\n",
      "Epoch: 59, Validation Loss: 218.7938, AUC Score: 0.6964\n",
      "Epoch: 60, Loss: 217.7814\n",
      "Epoch: 61, Loss: 217.1372\n",
      "Epoch: 62, Loss: 216.5361\n",
      "Epoch: 63, Loss: 215.9735\n",
      "Epoch: 64, Loss: 215.4459\n",
      "Epoch: 64, Validation Loss: 216.0935, AUC Score: 0.7002\n",
      "Epoch: 65, Loss: 214.9502\n",
      "Epoch: 66, Loss: 214.4836\n",
      "Epoch: 67, Loss: 214.0437\n",
      "Epoch: 68, Loss: 213.6283\n"
     ]
    }
   ],
   "source": [
    "# number of features and layers\n",
    "n_features = 2\n",
    "n_layers = 3\n",
    "\n",
    "# Random weight initialization\n",
    "weights = 0.01 * np.random.randn(n_layers, n_features, 3, requires_grad=True)\n",
    "\n",
    "# We create a quantum device with n_features \"wires\" (or qubits)\n",
    "dev = qml.device('default.qubit', wires=n_features)\n",
    "\n",
    "# train the model\n",
    "best_score, best_weights = train (n_features, n_layers,x_train,y_train_arr,0.01, weights, 100, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7339739775470611\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "auc_score = test(n_features, n_layers,x_test,y_test,w_test, best_weights)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type of rotation in  angle embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(n_features, n_layers, weights, x):\n",
    "        # Embedding\n",
    "        \n",
    "        qml.AngleEmbedding(x,range (0, n_features),rotation=\"Y\" )\n",
    "\n",
    "        # For every layer\n",
    "        for layer in range(n_layers):\n",
    "            W1 = weights[layer]\n",
    "\n",
    "            # Define Rotations\n",
    "            for i in range(0,n_features):\n",
    "                qml.Rot(W1[i, 0], W1[i, 1], W1[i, 2], wires=i)\n",
    "\n",
    "            # Entanglement\n",
    "            if n_features != 1:\n",
    "                if n_features > 2:\n",
    "                    for i in range(n_features):\n",
    "                        if i == n_features - 1:\n",
    "                            qml.CNOT(wires=[i, 0])\n",
    "                        else:\n",
    "                            qml.CNOT(wires=[i, i + 1])\n",
    "                else:\n",
    "                    qml.CNOT(wires=[1, 0])\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a392ad7533854705b137e7f3649781b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 258.5485\n",
      "Epoch: 1, Loss: 257.6502\n",
      "Epoch: 2, Loss: 256.5583\n",
      "Epoch: 3, Loss: 255.2702\n",
      "Epoch: 4, Loss: 253.7911\n",
      "Epoch: 5, Loss: 252.1263\n",
      "Epoch: 6, Loss: 250.2784\n",
      "Epoch: 7, Loss: 248.2543\n",
      "Epoch: 8, Loss: 246.0634\n",
      "Epoch: 9, Loss: 243.7140\n",
      "Epoch: 9, Validation Loss: 248.7585, AUC Score: 0.1085\n",
      "Epoch: 10, Loss: 241.2155\n",
      "Epoch: 11, Loss: 238.5806\n",
      "Epoch: 12, Loss: 235.8232\n",
      "Epoch: 13, Loss: 232.9568\n",
      "Epoch: 14, Loss: 229.9980\n",
      "Epoch: 15, Loss: 226.9645\n",
      "Epoch: 16, Loss: 223.8732\n",
      "Epoch: 17, Loss: 220.7421\n",
      "Epoch: 18, Loss: 217.5906\n",
      "Epoch: 19, Loss: 214.4355\n",
      "Epoch: 19, Validation Loss: 219.3143, AUC Score: 0.1096\n",
      "Epoch: 20, Loss: 211.2922\n",
      "Epoch: 21, Loss: 208.1762\n",
      "Epoch: 22, Loss: 205.1005\n",
      "Epoch: 23, Loss: 202.0744\n",
      "Epoch: 24, Loss: 199.1045\n",
      "Epoch: 25, Loss: 196.1948\n",
      "Epoch: 26, Loss: 193.3455\n",
      "Epoch: 27, Loss: 190.5537\n",
      "Epoch: 28, Loss: 187.8137\n",
      "Epoch: 29, Loss: 185.1173\n",
      "Epoch: 29, Validation Loss: 189.1727, AUC Score: 0.1121\n",
      "Epoch: 30, Loss: 182.4546\n",
      "Epoch: 31, Loss: 179.8147\n",
      "Epoch: 32, Loss: 177.1866\n",
      "Epoch: 33, Loss: 174.5607\n",
      "Epoch: 34, Loss: 171.9297\n",
      "Epoch: 35, Loss: 169.2894\n",
      "Epoch: 36, Loss: 166.6400\n",
      "Epoch: 37, Loss: 163.9865\n",
      "Epoch: 38, Loss: 161.3391\n",
      "Epoch: 39, Loss: 158.7121\n",
      "Epoch: 39, Validation Loss: 160.0925, AUC Score: 0.1124\n",
      "Epoch: 40, Loss: 156.1227\n",
      "Epoch: 41, Loss: 153.5860\n",
      "Epoch: 42, Loss: 151.1097\n",
      "Epoch: 43, Loss: 148.6938\n",
      "Epoch: 44, Loss: 146.3371\n",
      "Epoch: 45, Loss: 144.0406\n",
      "Epoch: 46, Loss: 141.8072\n",
      "Epoch: 47, Loss: 139.6405\n",
      "Epoch: 48, Loss: 137.5438\n",
      "Epoch: 49, Loss: 135.5195\n",
      "Epoch: 49, Validation Loss: 134.7507, AUC Score: 0.1272\n",
      "Epoch: 50, Loss: 133.5688\n",
      "Epoch: 51, Loss: 131.6918\n",
      "Epoch: 52, Loss: 129.8886\n",
      "Epoch: 53, Loss: 128.1596\n",
      "Epoch: 54, Loss: 126.5063\n",
      "Epoch: 55, Loss: 124.9304\n",
      "Epoch: 56, Loss: 123.4336\n",
      "Epoch: 57, Loss: 122.0172\n",
      "Epoch: 58, Loss: 120.6818\n",
      "Epoch: 59, Loss: 119.4270\n",
      "Epoch: 59, Validation Loss: 117.1778, AUC Score: 0.8641\n",
      "Epoch: 60, Loss: 118.2513\n",
      "Epoch: 61, Loss: 117.1521\n",
      "Epoch: 62, Loss: 116.1259\n",
      "Epoch: 63, Loss: 115.1684\n",
      "Epoch: 64, Loss: 114.2747\n",
      "Epoch: 65, Loss: 113.4398\n",
      "Epoch: 66, Loss: 112.6588\n",
      "Epoch: 67, Loss: 111.9271\n",
      "Epoch: 68, Loss: 111.2407\n",
      "Epoch: 69, Loss: 110.5962\n",
      "Epoch: 69, Validation Loss: 107.4021, AUC Score: 0.8806\n",
      "Epoch: 70, Loss: 109.9907\n",
      "Epoch: 71, Loss: 109.4220\n",
      "Epoch: 72, Loss: 108.8878\n",
      "Epoch: 73, Loss: 108.3861\n",
      "Epoch: 74, Loss: 107.9148\n",
      "Epoch: 75, Loss: 107.4713\n",
      "Epoch: 76, Loss: 107.0536\n",
      "Epoch: 77, Loss: 106.6592\n",
      "Epoch: 78, Loss: 106.2863\n",
      "Epoch: 79, Loss: 105.9331\n",
      "Epoch: 79, Validation Loss: 102.0854, AUC Score: 0.8828\n",
      "Epoch: 80, Loss: 105.5985\n",
      "Epoch: 81, Loss: 105.2812\n",
      "Epoch: 82, Loss: 104.9801\n",
      "Epoch: 83, Loss: 104.6942\n",
      "Epoch: 84, Loss: 104.4223\n",
      "Epoch: 85, Loss: 104.1634\n",
      "Epoch: 86, Loss: 103.9166\n",
      "Epoch: 87, Loss: 103.6809\n",
      "Epoch: 88, Loss: 103.4557\n",
      "Epoch: 89, Loss: 103.2403\n",
      "Epoch: 89, Validation Loss: 98.8756, AUC Score: 0.8845\n",
      "Epoch: 90, Loss: 103.0342\n",
      "Epoch: 91, Loss: 102.8369\n",
      "Epoch: 92, Loss: 102.6476\n",
      "Epoch: 93, Loss: 102.4661\n",
      "Epoch: 94, Loss: 102.2917\n",
      "Epoch: 95, Loss: 102.1240\n",
      "Epoch: 96, Loss: 101.9627\n",
      "Epoch: 97, Loss: 101.8073\n",
      "Epoch: 98, Loss: 101.6576\n",
      "Epoch: 99, Loss: 101.5133\n",
      "Epoch: 99, Validation Loss: 96.7215, AUC Score: 0.8861\n",
      "Best Score: 0.8861\n"
     ]
    }
   ],
   "source": [
    "# number of features and layers\n",
    "n_features = 2\n",
    "n_layers = 3\n",
    "\n",
    "# Random weight initialization\n",
    "weights = 0.01 * np.random.randn(n_layers, n_features, 3, requires_grad=True)\n",
    "\n",
    "# We create a quantum device with n_features \"wires\" (or qubits)\n",
    "dev = qml.device('default.qubit', wires=n_features)\n",
    "\n",
    "# train the model\n",
    "best_score, best_weights = train (n_features, n_layers,x_train,y_train_arr,0.01, weights, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7353790344559314\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "auc_score = test(n_features, n_layers,x_test,y_test,w_test, best_weights)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retirar rotaÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(n_features, n_layers, weights, x):\n",
    "        # Embedding\n",
    "        \n",
    "        qml.AngleEmbedding(x,range (0, n_features),rotation=\"X\" )\n",
    "\n",
    "        # For every layer\n",
    "        for layer in range(n_layers):\n",
    "            #W1 = weights[layer]\n",
    "\n",
    "            # Define Rotations\n",
    "            #for i in range(0,n_features):\n",
    "                #qml.Rot(W1[i, 0], W1[i, 1], W1[i, 2], wires=i)\n",
    "\n",
    "            # Entanglement\n",
    "            if n_features != 1:\n",
    "                if n_features > 2:\n",
    "                    for i in range(n_features):\n",
    "                        if i == n_features - 1:\n",
    "                            qml.CNOT(wires=[i, 0])\n",
    "                        else:\n",
    "                            qml.CNOT(wires=[i, i + 1])\n",
    "                else:\n",
    "                    qml.CNOT(wires=[1, 0])\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38672ac133ee45b78752a8410cae28d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 257.8696\n",
      "Epoch: 1, Loss: 257.8696\n",
      "Epoch: 2, Loss: 257.8696\n",
      "Epoch: 3, Loss: 257.8696\n",
      "Epoch: 4, Loss: 257.8696\n",
      "Epoch: 5, Loss: 257.8696\n",
      "Epoch: 6, Loss: 257.8696\n",
      "Epoch: 7, Loss: 257.8696\n",
      "Epoch: 8, Loss: 257.8696\n",
      "Epoch: 9, Loss: 257.8696\n",
      "Epoch: 9, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 10, Loss: 257.8696\n",
      "Epoch: 11, Loss: 257.8696\n",
      "Epoch: 12, Loss: 257.8696\n",
      "Epoch: 13, Loss: 257.8696\n",
      "Epoch: 14, Loss: 257.8696\n",
      "Epoch: 15, Loss: 257.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 257.8696\n",
      "Epoch: 17, Loss: 257.8696\n",
      "Epoch: 18, Loss: 257.8696\n",
      "Epoch: 19, Loss: 257.8696\n",
      "Epoch: 19, Validation Loss: 264.0529, AUC Score: 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 257.8696\n",
      "Epoch: 21, Loss: 257.8696\n",
      "Epoch: 22, Loss: 257.8696\n",
      "Epoch: 23, Loss: 257.8696\n",
      "Epoch: 24, Loss: 257.8696\n",
      "Epoch: 25, Loss: 257.8696\n",
      "Epoch: 26, Loss: 257.8696\n",
      "Epoch: 27, Loss: 257.8696\n",
      "Epoch: 28, Loss: 257.8696\n",
      "Epoch: 29, Loss: 257.8696\n",
      "Epoch: 29, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 30, Loss: 257.8696\n",
      "Epoch: 31, Loss: 257.8696\n",
      "Epoch: 32, Loss: 257.8696\n",
      "Epoch: 33, Loss: 257.8696\n",
      "Epoch: 34, Loss: 257.8696\n",
      "Epoch: 35, Loss: 257.8696\n",
      "Epoch: 36, Loss: 257.8696\n",
      "Epoch: 37, Loss: 257.8696\n",
      "Epoch: 38, Loss: 257.8696\n",
      "Epoch: 39, Loss: 257.8696\n",
      "Epoch: 39, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 40, Loss: 257.8696\n",
      "Epoch: 41, Loss: 257.8696\n",
      "Epoch: 42, Loss: 257.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n",
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Loss: 257.8696\n",
      "Epoch: 44, Loss: 257.8696\n",
      "Epoch: 45, Loss: 257.8696\n",
      "Epoch: 46, Loss: 257.8696\n",
      "Epoch: 47, Loss: 257.8696\n",
      "Epoch: 48, Loss: 257.8696\n",
      "Epoch: 49, Loss: 257.8696\n",
      "Epoch: 49, Validation Loss: 264.0529, AUC Score: 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 257.8696\n",
      "Epoch: 51, Loss: 257.8696\n",
      "Epoch: 52, Loss: 257.8696\n",
      "Epoch: 53, Loss: 257.8696\n",
      "Epoch: 54, Loss: 257.8696\n",
      "Epoch: 55, Loss: 257.8696\n",
      "Epoch: 56, Loss: 257.8696\n",
      "Epoch: 57, Loss: 257.8696\n",
      "Epoch: 58, Loss: 257.8696\n",
      "Epoch: 59, Loss: 257.8696\n",
      "Epoch: 59, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 60, Loss: 257.8696\n",
      "Epoch: 61, Loss: 257.8696\n",
      "Epoch: 62, Loss: 257.8696\n",
      "Epoch: 63, Loss: 257.8696\n",
      "Epoch: 64, Loss: 257.8696\n",
      "Epoch: 65, Loss: 257.8696\n",
      "Epoch: 66, Loss: 257.8696\n",
      "Epoch: 67, Loss: 257.8696\n",
      "Epoch: 68, Loss: 257.8696\n",
      "Epoch: 69, Loss: 257.8696\n",
      "Epoch: 69, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 70, Loss: 257.8696\n",
      "Epoch: 71, Loss: 257.8696\n",
      "Epoch: 72, Loss: 257.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n",
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Loss: 257.8696\n",
      "Epoch: 74, Loss: 257.8696\n",
      "Epoch: 75, Loss: 257.8696\n",
      "Epoch: 76, Loss: 257.8696\n",
      "Epoch: 77, Loss: 257.8696\n",
      "Epoch: 78, Loss: 257.8696\n",
      "Epoch: 79, Loss: 257.8696\n",
      "Epoch: 79, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 80, Loss: 257.8696\n",
      "Epoch: 81, Loss: 257.8696\n",
      "Epoch: 82, Loss: 257.8696\n",
      "Epoch: 83, Loss: 257.8696\n",
      "Epoch: 84, Loss: 257.8696\n",
      "Epoch: 85, Loss: 257.8696\n",
      "Epoch: 86, Loss: 257.8696\n",
      "Epoch: 87, Loss: 257.8696\n",
      "Epoch: 88, Loss: 257.8696\n",
      "Epoch: 89, Loss: 257.8696\n",
      "Epoch: 89, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Epoch: 90, Loss: 257.8696\n",
      "Epoch: 91, Loss: 257.8696\n",
      "Epoch: 92, Loss: 257.8696\n",
      "Epoch: 93, Loss: 257.8696\n",
      "Epoch: 94, Loss: 257.8696\n",
      "Epoch: 95, Loss: 257.8696\n",
      "Epoch: 96, Loss: 257.8696\n",
      "Epoch: 97, Loss: 257.8696\n",
      "Epoch: 98, Loss: 257.8696\n",
      "Epoch: 99, Loss: 257.8696\n",
      "Epoch: 99, Validation Loss: 264.0529, AUC Score: 0.1085\n",
      "Best Score: 0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n",
      "/home/brunasalgado/LIP/LIP_QML_2023/.envLip/lib/python3.9/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    }
   ],
   "source": [
    "# number of features and layers\n",
    "n_features = 2\n",
    "n_layers = 3\n",
    "\n",
    "# Random weight initialization\n",
    "weights = 0.01 * np.random.randn(n_layers, n_features, 3, requires_grad=True)\n",
    "\n",
    "# We create a quantum device with n_features \"wires\" (or qubits)\n",
    "dev = qml.device('default.qubit', wires=n_features)\n",
    "\n",
    "# train the model\n",
    "best_score, best_weights = train (n_features, n_layers,x_train,y_train_arr,0.01, weights, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25819930973022687\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "auc_score = test(n_features, n_layers,x_test,y_test,w_test, best_weights)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retirar entanglement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(n_features, n_layers, weights, x):\n",
    "        # Embedding\n",
    "        \n",
    "        qml.AngleEmbedding(x,range (0, n_features),rotation=\"Y\" )\n",
    "\n",
    "        # For every layer\n",
    "        for layer in range(n_layers):\n",
    "            W1 = weights[layer]\n",
    "\n",
    "            # Define Rotations\n",
    "            for i in range(0,n_features):\n",
    "                qml.Rot(W1[i, 0], W1[i, 1], W1[i, 2], wires=i)\n",
    "\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa319f618fca4acf83104cd61abf9e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 166.4724\n",
      "Epoch: 1, Loss: 163.5699\n",
      "Epoch: 2, Loss: 160.6324\n",
      "Epoch: 3, Loss: 157.6568\n",
      "Epoch: 4, Loss: 154.6489\n",
      "Epoch: 5, Loss: 151.6227\n",
      "Epoch: 6, Loss: 148.5940\n",
      "Epoch: 7, Loss: 145.5718\n",
      "Epoch: 8, Loss: 142.5558\n",
      "Epoch: 9, Loss: 139.5553\n",
      "Epoch: 9, Validation Loss: 128.1398, AUC Score: 0.8914\n",
      "Epoch: 10, Loss: 136.5854\n",
      "Epoch: 11, Loss: 133.6609\n",
      "Epoch: 12, Loss: 130.7916\n",
      "Epoch: 13, Loss: 127.9825\n",
      "Epoch: 14, Loss: 125.2430\n",
      "Epoch: 15, Loss: 122.5864\n",
      "Epoch: 16, Loss: 120.0259\n",
      "Epoch: 17, Loss: 117.5706\n",
      "Epoch: 18, Loss: 115.2263\n",
      "Epoch: 19, Loss: 113.0003\n",
      "Epoch: 19, Validation Loss: 102.5228, AUC Score: 0.8902\n",
      "Epoch: 20, Loss: 110.9015\n",
      "Epoch: 21, Loss: 108.9384\n",
      "Epoch: 22, Loss: 107.1162\n",
      "Epoch: 23, Loss: 105.4373\n",
      "Epoch: 24, Loss: 103.9034\n",
      "Epoch: 25, Loss: 102.5161\n",
      "Epoch: 26, Loss: 101.2762\n",
      "Epoch: 27, Loss: 100.1818\n",
      "Epoch: 28, Loss: 99.2288\n",
      "Epoch: 29, Loss: 98.4116\n",
      "Epoch: 29, Validation Loss: 89.9679, AUC Score: 0.8878\n",
      "Epoch: 30, Loss: 97.7234\n",
      "Epoch: 31, Loss: 97.1567\n",
      "Epoch: 32, Loss: 96.7026\n",
      "Epoch: 33, Loss: 96.3511\n",
      "Epoch: 34, Loss: 96.0913\n",
      "Epoch: 35, Loss: 95.9118\n",
      "Epoch: 36, Loss: 95.8011\n",
      "Epoch: 37, Loss: 95.7477\n",
      "Epoch: 38, Loss: 95.7405\n",
      "Epoch: 39, Loss: 95.7689\n",
      "Epoch: 39, Validation Loss: 88.6945, AUC Score: 0.8853\n",
      "Epoch: 40, Loss: 95.8229\n",
      "Epoch: 41, Loss: 95.8937\n",
      "Epoch: 42, Loss: 95.9733\n",
      "Epoch: 43, Loss: 96.0550\n",
      "Epoch: 44, Loss: 96.1331\n",
      "Epoch: 45, Loss: 96.2033\n",
      "Epoch: 46, Loss: 96.2621\n",
      "Epoch: 47, Loss: 96.3072\n",
      "Epoch: 48, Loss: 96.3373\n",
      "Epoch: 49, Loss: 96.3516\n",
      "Epoch: 49, Validation Loss: 89.4292, AUC Score: 0.8837\n",
      "Epoch: 50, Loss: 96.3497\n",
      "Epoch: 51, Loss: 96.3319\n",
      "Epoch: 52, Loss: 96.2986\n",
      "Epoch: 53, Loss: 96.2512\n",
      "Epoch: 54, Loss: 96.1924\n",
      "Epoch: 55, Loss: 96.1264\n",
      "Epoch: 56, Loss: 96.0594\n",
      "Epoch: 57, Loss: 95.9983\n",
      "Epoch: 58, Loss: 95.9505\n",
      "Epoch: 59, Loss: 95.9207\n",
      "Epoch: 59, Validation Loss: 88.8745, AUC Score: 0.8856\n",
      "Epoch: 60, Loss: 95.9087\n",
      "Epoch: 61, Loss: 95.9075\n",
      "Epoch: 62, Loss: 95.9063\n",
      "Epoch: 63, Loss: 95.8974\n",
      "Epoch: 64, Loss: 95.8794\n",
      "Epoch: 65, Loss: 95.8557\n",
      "Epoch: 66, Loss: 95.8303\n",
      "Epoch: 67, Loss: 95.8068\n",
      "Epoch: 68, Loss: 95.7872\n",
      "Epoch: 69, Loss: 95.7721\n",
      "Epoch: 69, Validation Loss: 88.5608, AUC Score: 0.8858\n",
      "Epoch: 70, Loss: 95.7611\n",
      "Epoch: 71, Loss: 95.7536\n",
      "Epoch: 72, Loss: 95.7487\n",
      "Epoch: 73, Loss: 95.7457\n",
      "Epoch: 74, Loss: 95.7441\n",
      "Epoch: 75, Loss: 95.7435\n",
      "Epoch: 76, Loss: 95.7436\n",
      "Epoch: 77, Loss: 95.7442\n",
      "Epoch: 78, Loss: 95.7451\n",
      "Epoch: 79, Loss: 95.7461\n",
      "Epoch: 79, Validation Loss: 88.5173, AUC Score: 0.8859\n",
      "Epoch: 80, Loss: 95.7471\n",
      "Epoch: 81, Loss: 95.7479\n",
      "Epoch: 82, Loss: 95.7486\n",
      "Epoch: 83, Loss: 95.7489\n",
      "Epoch: 84, Loss: 95.7490\n",
      "Epoch: 85, Loss: 95.7489\n",
      "Epoch: 86, Loss: 95.7485\n",
      "Epoch: 87, Loss: 95.7481\n",
      "Epoch: 88, Loss: 95.7475\n",
      "Epoch: 89, Loss: 95.7470\n",
      "Epoch: 89, Validation Loss: 88.4778, AUC Score: 0.8861\n",
      "Epoch: 90, Loss: 95.7464\n",
      "Epoch: 91, Loss: 95.7458\n",
      "Epoch: 92, Loss: 95.7452\n",
      "Epoch: 93, Loss: 95.7445\n",
      "Epoch: 94, Loss: 95.7438\n",
      "Epoch: 95, Loss: 95.7431\n",
      "Epoch: 96, Loss: 95.7423\n",
      "Epoch: 97, Loss: 95.7415\n",
      "Epoch: 98, Loss: 95.7407\n",
      "Epoch: 99, Loss: 95.7400\n",
      "Epoch: 99, Validation Loss: 88.4814, AUC Score: 0.8860\n",
      "Best Score: 0.8914\n"
     ]
    }
   ],
   "source": [
    "# number of features and layers\n",
    "n_features = 2\n",
    "n_layers = 3\n",
    "\n",
    "# Random weight initialization\n",
    "weights = 0.01 * np.random.randn(n_layers, n_features, 3, requires_grad=True)\n",
    "\n",
    "# We create a quantum device with n_features \"wires\" (or qubits)\n",
    "dev = qml.device('default.qubit', wires=n_features)\n",
    "\n",
    "# train the model\n",
    "best_score, best_weights = train (n_features, n_layers,x_train,y_train_arr,0.01, weights, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7415599779037287\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "auc_score = test(n_features, n_layers,x_test,y_test,w_test, best_weights)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substituir CNOTs por CZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantum circuit function\n",
    "def circuit(n_features, n_layers, weights, x):\n",
    "        # Embedding\n",
    "        \n",
    "        qml.AngleEmbedding(x,range (0, n_features),rotation=\"X\" )\n",
    "\n",
    "        # For every layer\n",
    "        for layer in range(n_layers):\n",
    "            W1 = weights[layer]\n",
    "\n",
    "            # Define Rotations\n",
    "            for i in range(0,n_features):\n",
    "                qml.Rot(W1[i, 0], W1[i, 1], W1[i, 2], wires=i)\n",
    "\n",
    "            # Entanglement\n",
    "            if n_features != 1:\n",
    "                if n_features > 2:\n",
    "                    for i in range(n_features):\n",
    "                        if i == n_features - 1:\n",
    "                            qml.CZ(wires=[i, 0])\n",
    "                        else:\n",
    "                            qml.CZ(wires=[i, i + 1])\n",
    "                else:\n",
    "                    qml.CZ(wires=[1, 0])\n",
    "\n",
    "        return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c287d4a80d6417f826152d87d15d757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 166.1363\n",
      "Epoch: 1, Loss: 166.0886\n",
      "Epoch: 2, Loss: 165.9619\n",
      "Epoch: 3, Loss: 165.6897\n",
      "Epoch: 4, Loss: 165.2375\n",
      "Epoch: 5, Loss: 164.5753\n",
      "Epoch: 6, Loss: 163.6866\n",
      "Epoch: 7, Loss: 162.5604\n",
      "Epoch: 8, Loss: 161.1900\n",
      "Epoch: 9, Loss: 159.5728\n",
      "Epoch: 9, Validation Loss: 150.1490, AUC Score: 0.8915\n",
      "Epoch: 10, Loss: 157.7106\n",
      "Epoch: 11, Loss: 155.6095\n",
      "Epoch: 12, Loss: 153.2802\n",
      "Epoch: 13, Loss: 150.7378\n",
      "Epoch: 14, Loss: 148.0018\n",
      "Epoch: 15, Loss: 145.0960\n",
      "Epoch: 16, Loss: 142.0485\n",
      "Epoch: 17, Loss: 138.8908\n",
      "Epoch: 18, Loss: 135.6577\n",
      "Epoch: 19, Loss: 132.3857\n",
      "Epoch: 19, Validation Loss: 121.7375, AUC Score: 0.8914\n",
      "Epoch: 20, Loss: 129.1130\n",
      "Epoch: 21, Loss: 125.8779\n",
      "Epoch: 22, Loss: 122.7176\n",
      "Epoch: 23, Loss: 119.6670\n",
      "Epoch: 24, Loss: 116.7577\n",
      "Epoch: 25, Loss: 114.0168\n",
      "Epoch: 26, Loss: 111.4663\n",
      "Epoch: 27, Loss: 109.1221\n",
      "Epoch: 28, Loss: 106.9946\n",
      "Epoch: 29, Loss: 105.0886\n",
      "Epoch: 29, Validation Loss: 96.2832, AUC Score: 0.8886\n",
      "Epoch: 30, Loss: 103.4038\n",
      "Epoch: 31, Loss: 101.9354\n",
      "Epoch: 32, Loss: 100.6753\n",
      "Epoch: 33, Loss: 99.6123\n",
      "Epoch: 34, Loss: 98.7333\n",
      "Epoch: 35, Loss: 98.0232\n",
      "Epoch: 36, Loss: 97.4657\n",
      "Epoch: 37, Loss: 97.0435\n",
      "Epoch: 38, Loss: 96.7388\n",
      "Epoch: 39, Loss: 96.5331\n",
      "Epoch: 39, Validation Loss: 89.6670, AUC Score: 0.8865\n",
      "Epoch: 40, Loss: 96.4083\n",
      "Epoch: 41, Loss: 96.3463\n",
      "Epoch: 42, Loss: 96.3303\n",
      "Epoch: 43, Loss: 96.3446\n",
      "Epoch: 44, Loss: 96.3750\n",
      "Epoch: 45, Loss: 96.4096\n",
      "Epoch: 46, Loss: 96.4390\n",
      "Epoch: 47, Loss: 96.4560\n",
      "Epoch: 48, Loss: 96.4561\n",
      "Epoch: 49, Loss: 96.4374\n",
      "Epoch: 49, Validation Loss: 89.6820, AUC Score: 0.8846\n",
      "Epoch: 50, Loss: 96.4001\n",
      "Epoch: 51, Loss: 96.3464\n",
      "Epoch: 52, Loss: 96.2801\n",
      "Epoch: 53, Loss: 96.2061\n",
      "Epoch: 54, Loss: 96.1299\n",
      "Epoch: 55, Loss: 96.0567\n",
      "Epoch: 56, Loss: 95.9916\n",
      "Epoch: 57, Loss: 95.9387\n",
      "Epoch: 58, Loss: 95.9008\n",
      "Epoch: 59, Loss: 95.8785\n",
      "Epoch: 59, Validation Loss: 88.7652, AUC Score: 0.8858\n",
      "Epoch: 60, Loss: 95.8697\n",
      "Epoch: 61, Loss: 95.8700\n",
      "Epoch: 62, Loss: 95.8741\n",
      "Epoch: 63, Loss: 95.8784\n",
      "Epoch: 64, Loss: 95.8805\n",
      "Epoch: 65, Loss: 95.8796\n",
      "Epoch: 66, Loss: 95.8755\n",
      "Epoch: 67, Loss: 95.8684\n",
      "Epoch: 68, Loss: 95.8589\n",
      "Epoch: 69, Loss: 95.8478\n",
      "Epoch: 69, Validation Loss: 88.5776, AUC Score: 0.8864\n",
      "Epoch: 70, Loss: 95.8360\n",
      "Epoch: 71, Loss: 95.8241\n",
      "Epoch: 72, Loss: 95.8129\n",
      "Epoch: 73, Loss: 95.8028\n",
      "Epoch: 74, Loss: 95.7942\n",
      "Epoch: 75, Loss: 95.7871\n",
      "Epoch: 76, Loss: 95.7818\n",
      "Epoch: 77, Loss: 95.7779\n",
      "Epoch: 78, Loss: 95.7753\n",
      "Epoch: 79, Loss: 95.7738\n",
      "Epoch: 79, Validation Loss: 88.5686, AUC Score: 0.8859\n",
      "Epoch: 80, Loss: 95.7731\n",
      "Epoch: 81, Loss: 95.7728\n",
      "Epoch: 82, Loss: 95.7728\n",
      "Epoch: 83, Loss: 95.7728\n",
      "Epoch: 84, Loss: 95.7726\n",
      "Epoch: 85, Loss: 95.7722\n",
      "Epoch: 86, Loss: 95.7716\n",
      "Epoch: 87, Loss: 95.7707\n",
      "Epoch: 88, Loss: 95.7697\n",
      "Epoch: 89, Loss: 95.7685\n",
      "Epoch: 89, Validation Loss: 88.5631, AUC Score: 0.8859\n",
      "Epoch: 90, Loss: 95.7673\n",
      "Epoch: 91, Loss: 95.7661\n",
      "Epoch: 92, Loss: 95.7650\n",
      "Epoch: 93, Loss: 95.7641\n",
      "Epoch: 94, Loss: 95.7633\n",
      "Epoch: 95, Loss: 95.7626\n",
      "Epoch: 96, Loss: 95.7620\n",
      "Epoch: 97, Loss: 95.7615\n",
      "Epoch: 98, Loss: 95.7611\n",
      "Epoch: 99, Loss: 95.7607\n",
      "Epoch: 99, Validation Loss: 88.5213, AUC Score: 0.8861\n",
      "Best Score: 0.8915\n"
     ]
    }
   ],
   "source": [
    "# number of features and layers\n",
    "n_features = 2\n",
    "n_layers = 3\n",
    "\n",
    "# Random weight initialization\n",
    "weights = 0.01 * np.random.randn(n_layers, n_features, 3, requires_grad=True)\n",
    "\n",
    "# We create a quantum device with n_features \"wires\" (or qubits)\n",
    "dev = qml.device('default.qubit', wires=n_features)\n",
    "\n",
    "# train the model\n",
    "best_score, best_weights = train (n_features, n_layers,x_train,y_train_arr,0.01, weights, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7417816820371923\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "auc_score = test(n_features, n_layers,x_test,y_test,w_test, best_weights)\n",
    "print (auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medir o segundo qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(n_features, n_layers, weights, x):\n",
    "        # Embedding\n",
    "        \n",
    "        qml.AngleEmbedding(x,range (0, n_features),rotation=\"Y\" )\n",
    "\n",
    "        # For every layer\n",
    "        for layer in range(n_layers):\n",
    "            W1 = weights[layer]\n",
    "\n",
    "            # Define Rotations\n",
    "            for i in range(0,n_features):\n",
    "                qml.Rot(W1[i, 0], W1[i, 1], W1[i, 2], wires=i)\n",
    "\n",
    "            # Entanglement\n",
    "            if n_features != 1:\n",
    "                if n_features > 2:\n",
    "                    for i in range(n_features):\n",
    "                        if i == n_features - 1:\n",
    "                            qml.CNOT(wires=[i, 0])\n",
    "                        else:\n",
    "                            qml.CNOT(wires=[i, i + 1])\n",
    "                else:\n",
    "                    qml.CNOT(wires=[1, 0])\n",
    "\n",
    "        return qml.expval(qml.PauliZ(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bb25e72a074322a1ea565b94ff9ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 249.9795\n",
      "Epoch: 1, Loss: 249.8142\n",
      "Epoch: 2, Loss: 249.5087\n",
      "Epoch: 3, Loss: 249.0463\n",
      "Epoch: 4, Loss: 248.4191\n",
      "Epoch: 5, Loss: 247.6203\n",
      "Epoch: 6, Loss: 246.6436\n",
      "Epoch: 7, Loss: 245.4829\n",
      "Epoch: 8, Loss: 244.1333\n",
      "Epoch: 9, Loss: 242.5903\n",
      "Epoch: 9, Validation Loss: 240.7502, AUC Score: 0.8550\n",
      "Epoch: 10, Loss: 240.8503\n",
      "Epoch: 11, Loss: 238.9108\n",
      "Epoch: 12, Loss: 236.7710\n",
      "Epoch: 13, Loss: 234.4305\n",
      "Epoch: 14, Loss: 231.8906\n",
      "Epoch: 15, Loss: 229.1553\n",
      "Epoch: 16, Loss: 226.2289\n",
      "Epoch: 17, Loss: 223.1177\n",
      "Epoch: 18, Loss: 219.8311\n",
      "Epoch: 19, Loss: 216.3793\n",
      "Epoch: 19, Validation Loss: 212.5456, AUC Score: 0.8295\n",
      "Epoch: 20, Loss: 212.7745\n",
      "Epoch: 21, Loss: 209.0317\n",
      "Epoch: 22, Loss: 205.1672\n",
      "Epoch: 23, Loss: 201.1988\n",
      "Epoch: 24, Loss: 197.1458\n",
      "Epoch: 25, Loss: 193.0287\n",
      "Epoch: 26, Loss: 188.8676\n",
      "Epoch: 27, Loss: 184.6834\n",
      "Epoch: 28, Loss: 180.4975\n",
      "Epoch: 29, Loss: 176.3319\n",
      "Epoch: 29, Validation Loss: 171.9730, AUC Score: 0.7974\n",
      "Epoch: 30, Loss: 172.2096\n",
      "Epoch: 31, Loss: 168.1539\n",
      "Epoch: 32, Loss: 164.1880\n",
      "Epoch: 33, Loss: 160.3344\n",
      "Epoch: 34, Loss: 156.6138\n",
      "Epoch: 35, Loss: 153.0450\n",
      "Epoch: 36, Loss: 149.6441\n",
      "Epoch: 37, Loss: 146.4237\n",
      "Epoch: 38, Loss: 143.3928\n",
      "Epoch: 39, Loss: 140.5567\n",
      "Epoch: 39, Validation Loss: 137.5861, AUC Score: 0.7889\n",
      "Epoch: 40, Loss: 137.9164\n",
      "Epoch: 41, Loss: 135.4698\n",
      "Epoch: 42, Loss: 133.2118\n",
      "Epoch: 43, Loss: 131.1349\n",
      "Epoch: 44, Loss: 129.2296\n",
      "Epoch: 45, Loss: 127.4852\n",
      "Epoch: 46, Loss: 125.8900\n",
      "Epoch: 47, Loss: 124.4312\n",
      "Epoch: 48, Loss: 123.0959\n",
      "Epoch: 49, Loss: 121.8711\n",
      "Epoch: 49, Validation Loss: 119.7483, AUC Score: 0.8197\n",
      "Epoch: 50, Loss: 120.7438\n",
      "Epoch: 51, Loss: 119.7018\n",
      "Epoch: 52, Loss: 118.7335\n",
      "Epoch: 53, Loss: 117.8284\n",
      "Epoch: 54, Loss: 116.9773\n",
      "Epoch: 55, Loss: 116.1721\n",
      "Epoch: 56, Loss: 115.4059\n",
      "Epoch: 57, Loss: 114.6732\n",
      "Epoch: 58, Loss: 113.9692\n",
      "Epoch: 59, Loss: 113.2897\n",
      "Epoch: 59, Validation Loss: 110.5663, AUC Score: 0.8521\n",
      "Epoch: 60, Loss: 112.6312\n",
      "Epoch: 61, Loss: 111.9924\n",
      "Epoch: 62, Loss: 111.3752\n",
      "Epoch: 63, Loss: 110.7831\n",
      "Epoch: 64, Loss: 110.2184\n",
      "Epoch: 65, Loss: 109.6861\n",
      "Epoch: 66, Loss: 109.1888\n",
      "Epoch: 67, Loss: 108.7249\n",
      "Epoch: 68, Loss: 108.2883\n",
      "Epoch: 69, Loss: 107.8711\n",
      "Epoch: 69, Validation Loss: 104.3304, AUC Score: 0.8662\n",
      "Epoch: 70, Loss: 107.4700\n",
      "Epoch: 71, Loss: 107.0834\n",
      "Epoch: 72, Loss: 106.7111\n",
      "Epoch: 73, Loss: 106.3539\n",
      "Epoch: 74, Loss: 106.0119\n",
      "Epoch: 75, Loss: 105.6859\n",
      "Epoch: 76, Loss: 105.3760\n",
      "Epoch: 77, Loss: 105.0821\n",
      "Epoch: 78, Loss: 104.8042\n",
      "Epoch: 79, Loss: 104.5420\n",
      "Epoch: 79, Validation Loss: 100.3925, AUC Score: 0.8721\n",
      "Epoch: 80, Loss: 104.2943\n",
      "Epoch: 81, Loss: 104.0599\n",
      "Epoch: 82, Loss: 103.8368\n",
      "Epoch: 83, Loss: 103.6230\n",
      "Epoch: 84, Loss: 103.4168\n",
      "Epoch: 85, Loss: 103.2162\n",
      "Epoch: 86, Loss: 103.0200\n",
      "Epoch: 87, Loss: 102.8277\n",
      "Epoch: 88, Loss: 102.6390\n",
      "Epoch: 89, Loss: 102.4544\n",
      "Epoch: 89, Validation Loss: 97.8426, AUC Score: 0.8783\n",
      "Epoch: 90, Loss: 102.2745\n",
      "Epoch: 91, Loss: 102.0997\n",
      "Epoch: 92, Loss: 101.9308\n",
      "Epoch: 93, Loss: 101.7681\n",
      "Epoch: 94, Loss: 101.6118\n",
      "Epoch: 95, Loss: 101.4620\n",
      "Epoch: 96, Loss: 101.3184\n",
      "Epoch: 97, Loss: 101.1808\n",
      "Epoch: 98, Loss: 101.0488\n",
      "Epoch: 99, Loss: 100.9219\n",
      "Epoch: 99, Validation Loss: 96.0099, AUC Score: 0.8796\n",
      "Best Score: 0.8796\n"
     ]
    }
   ],
   "source": [
    "# number of features and layers\n",
    "n_features = 2\n",
    "n_layers = 3\n",
    "\n",
    "# Random weight initialization\n",
    "weights = 0.01 * np.random.randn(n_layers, n_features, 3, requires_grad=True)\n",
    "\n",
    "# We create a quantum device with n_features \"wires\" (or qubits)\n",
    "dev = qml.device('default.qubit', wires=n_features)\n",
    "\n",
    "# train the model\n",
    "best_score, best_weights = train (n_features, n_layers,x_train,y_train_arr,0.01, weights, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7302230317327565\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "auc_score = test(n_features, n_layers,x_test,y_test,w_test, best_weights)\n",
    "print (auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
